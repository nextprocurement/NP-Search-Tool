{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad642cb4-ad96-41db-abfb-ca55701f5d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d651b07c",
   "metadata": {},
   "source": [
    "# Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc24491",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_env = pathlib.Path('/export/usuarios_ml4ds/cggamella/NP-Search-Tool/.env')\n",
    "print(f\"Ruta al archivo .env: {path_env}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a3d8a6-e9e7-4f7e-8c9e-307add95ea97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_env = pathlib.Path(os.getcwd()).parent.parent / '.env'\n",
    "path_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1164974a-17f3-4a27-8460-a2ae024fc04c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_dotenv(path_env)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a12625a-53aa-439f-bd0d-59c4caf354b2",
   "metadata": {},
   "source": [
    "## Create VectorDB with parquet docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fdf68f-c800-4f29-88b0-72a93f049c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/export/usuarios_ml4ds/cggamella/NP-Company-Process/data/DESCARGAS_ENTREGABLES/outsiders.parquet'\n",
    "df_out = pd.read_parquet(path)\n",
    "\n",
    "def unify_colname(col):\n",
    "    return \".\".join([el for el in col if el])\n",
    "\n",
    "df_out.columns = [unify_colname(col) for col in df_out.columns]\n",
    "\n",
    "index_names = df_out.index.names\n",
    "#Se resetea el índice sobre el propio dataframe\n",
    "df_out.reset_index(inplace=True)\n",
    "#Crear identifier con los index_names separados con '/', así generamos un id único para cada fila\n",
    "df_out[\"identifier\"] = df_out[index_names].astype(str).agg(\"/\".join, axis=1)\n",
    "#Filtrado para quedarme con esas 2 cols\n",
    "df_out = df_out[['identifier', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eabc2f-7fb2-40e1-8cf4-df31767480ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear el text splitter, [chunk_size: #caracteres de cada chunk];\n",
    "#[chunk_overlap: #caracteres solapan entre chunks para no perder info.]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# Crear una lista para almacenar los documentos\n",
    "documents = []\n",
    "# Procesar cada fila como un documento separado\n",
    "for idx, row in df_out.iterrows():\n",
    "    example_document = row['title']\n",
    "    #print(\"el example doc es:\",example_document)\n",
    "    doc = Document(page_content=example_document, metadata={\"url\": \"local\", \"source\": \"initial\", \"identifier\": row['identifier']})\n",
    "    #print(\"El doc es:\",doc)\n",
    "    # Dividir el documento en fragmentos\n",
    "    chunks = text_splitter.split_text(doc.page_content)\n",
    "    #print(\"Los chunks son:\",chunks)\n",
    "    for chunk in chunks:\n",
    "        chunk_doc = Document(page_content=chunk, metadata=doc.metadata)\n",
    "        #print(\"EL chunk_doc es:\\n\",chunk_doc)\n",
    "        documents.append(chunk_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aad4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and store the texts\n",
    "path_to_index = '/export/usuarios_ml4ds/cggamella/NP-Search-Tool/aux_scripts/RAG'\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = (pathlib.Path(path_to_index) / 'db').as_posix()\n",
    "\n",
    "start = time.time()\n",
    "# Define embeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# Almacenar los fragmentos en una base de datos vectorial usando Chroma\n",
    "# Se extrae el contenido (page_content).El contenido se pasa a OpenAIEmbeddings\n",
    "# para obtener embeddings. El vector resultante se almacena en la base de datos junto con los metadatos(índices).\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory \n",
    ")\n",
    "# Tiempo total de ejecución\n",
    "end = time.time()\n",
    "print(f\"Total time is {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a5dba2-4045-4ba3-a8d9-466a9c7b0674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Given the word \"{acronym}\", understand that an acronym word is a type of abbreviation formed by taking the initial\n",
    "letters or parts of words from a phrase or term and combining them to form a new word. Acronyms are pronounced\n",
    "as words themselves, rather than being spelled out letter by letter. \n",
    "\n",
    "For example, \"aeat\" stands for \"agencia_estatal_de_administración_tributaria\", \"csic\" stands for \"consejo_superior_de_investigaciones_científicas\", \"ceip\" stands for \"colegio_educación_infantil_y_primaria\", and \"avda\" stands for \"avenida\".\n",
    "Additionally, abbreviations can be formed by taking the initial letters of a phrase (like acronyms), by using only some letters of a word (like \"Dr.\" for \"Doctor\"), or by shortening a word (like \"apt.\" for \"apartmento\"). \n",
    "\n",
    "Please provide the full expression of the acronym in the following dictionary format: 'acronym:expanded_word',\n",
    "where spaces between words are replaced by underscores '_'. If the expanded word is too long or if there is any other issue, do NOT provide an answer.\n",
    "\n",
    "Documents:\n",
    "{summaries}\n",
    "\n",
    "--------------------\n",
    "If you find any issue finding the correct expression, your answer have the following format: ''. Otherwise, your answer should be 'acronym:expanded_word'.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02e803e-2fae-4981-92e3-0d9680b55733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the turbo LLM\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    model_name='gpt-4o'\n",
    ")\n",
    "\n",
    "# Crear la chain\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5}),\n",
    "    chain_type=\"stuff\",\n",
    "    verbose=True,\n",
    "    chain_type_kwargs={\n",
    "        \"verbose\": True,\n",
    "        \"prompt\": prompt_template,\n",
    "    }\n",
    ")\n",
    "\n",
    "def generate_acronym_expansions(chain, acronyms):\n",
    "    results = {}\n",
    "    for acronym in acronyms:\n",
    "        # Recuperar documentos relevantes utilizando el retriever\n",
    "        retrieved_docs = chain.retriever.get_relevant_documents(acronym)\n",
    "        # Crear el resumen de documentos\n",
    "        summaries = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "        # Formar el prompt utilizando el template\n",
    "        prompt = prompt_template.format(acronym=acronym, summaries=summaries)\n",
    "        # Ejecutar la cadena con el prompt usando invoke\n",
    "        response = chain.invoke({\"question\": prompt, \"acronym\": acronym, \"summaries\": summaries})\n",
    "        print(f\"Respuesta del modelo para '{acronym}':\\n{response}\\n\")\n",
    "        # Obtener la respuesta del modelo de lenguaje\n",
    "        answer = response['answer']\n",
    "        # Parsear la respuesta y agregarla a los resultados\n",
    "        results[acronym] = answer.strip()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ef1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de acrónimos a buscar\n",
    "acronyms = ['ghz','ecc','vga','s.l']# 's.a.', 'bop', 'pcap', 'ceip', 'jjmm', 'smp', 'avda', 'ffcc', 'itv']\n",
    "\n",
    "# Generar las expansiones de los acrónimos\n",
    "acronym_expansions = generate_acronym_expansions(chain, acronyms)\n",
    "\n",
    "# Imprimir los resultados\n",
    "for acronym, expansion in acronym_expansions.items():\n",
    "    print(f\"{acronym}: {expansion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0328b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acronym_expansions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6049a7b1",
   "metadata": {},
   "source": [
    "# NP-Search-Tool sacar acrónimos con RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528efa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install chromadb\n",
    "#!pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080292fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e564ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/export/usuarios_ml4ds/cggamella/NP-Company-Process/data/DESCARGAS_ENTREGABLES/outsiders.parquet'\n",
    "df_out = pd.read_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6a3d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_colname(col):\n",
    "    return \".\".join([el for el in col if el])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4079bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.columns = [unify_colname(col) for col in df_out.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para coger ['zip', 'file name', 'entry']\n",
    "index_names = df_out.index.names\n",
    "#Se resetea el índice sobre el propio dataframe\n",
    "df_out.reset_index(inplace=True)\n",
    "#Pone como identifier los index names separados con '/', así generamos un id único para cada fila\n",
    "df_out[\"identifier\"] = df_out[index_names].astype(str).agg(\"/\".join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c50a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_out.loc[:100, ['identifier', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1488ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la longitud media de la columna 'title'\n",
    "df_filtered['title_length'] = df_filtered['title'].apply(len)\n",
    "average_length = df_filtered['title_length'].mean()\n",
    "average_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aada9e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el modelo de embeddings\n",
    "model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2', device='cuda')\n",
    "# Generar embeddings para cada título en el dataframe\n",
    "embeddings = model.encode(df_out['title'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc19a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context_similarity(acronym, embeddings, df_out):\n",
    "    acronym_embedding = model.encode([acronym])\n",
    "    #print(\"La query embedding es:\\n\", query_embedding)\n",
    "    similarities = cosine_similarity(acronym_embedding, embeddings)[0]\n",
    "    print(\"Las cosine similarities son:\\n\", similarities)\n",
    "    most_similar_indices = np.argsort(similarities)[-10:][::-1]\n",
    "    print(\"Los indices mas similares son:\\n\", most_similar_indices)\n",
    "    results = [df_out['title'].iloc[i] for i in most_similar_indices]\n",
    "    print(\"Los resultados del retrieve son:\\n\", results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1abcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context_contain_acronym(acronym, df_out):\n",
    "    # Crear el patrón de expresión regular para coincidir con la palabra exacta\n",
    "    pattern = re.compile(r'\\b' + re.escape(acronym) + r'\\b', re.IGNORECASE)\n",
    "    # Filtrar los títulos que contienen el acrónimo exacto\n",
    "    results = df_out[df_out['title'].str.contains(pattern, na=False)]\n",
    "    # Obtener los títulos y limitar a los primeros 5 documentos\n",
    "    titles = results['title'].head(5).tolist()\n",
    "    # Limitar cada título a los primeros 70 caracteres\n",
    "    limited_titles = [title[:70] for title in titles]\n",
    "    return limited_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee550aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()\n",
    "             \n",
    "def generate_equivalent_expression(acronym):\n",
    "    contexts = retrieve_context_similarity(acronym, embeddings, df_out)    \n",
    "    context_texts = \" \".join(contexts)\n",
    "    prompt = f\"Given the acronym {acronym}, and the following context: {context_texts}, provide the large expression of the acronym. Please provide me the result in a dictionary format 'acronym:equivalence'\"\n",
    "    print(\"EL PROMPTING ES:\", prompt)\n",
    "    response = llm.generate([prompt])\n",
    "    print(\"La respuesta es:\", response)\n",
    "    return response.generations[0][0].text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ca732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acronyms = ['ghz','ecc','vga','s.l', 's.a.', 'bop', 'pcap', 'ceip', 'jjmm', 'smp', 'avda', 'ffcc', 'itv']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b956f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for acronym in acronyms:\n",
    "    expression = generate_equivalent_expression(acronym)\n",
    "    results[acronym] = expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe45bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estos son los resultados con la función de retrieve_context_similarity\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estos son los resultados con la función de retrieve_context_contain_acronym\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d763f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out['title'].iloc[36711]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a46a64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir cada título en palabras y seleccionar aquellas con 3 letras\n",
    "#words_3 = df_out['title'].str.split().explode().str.lower().apply(lambda x: x.strip(',.')).loc[lambda x: x.str.len() == 4]\n",
    "# Convertir las palabras seleccionadas en una lista\n",
    "#words_list = words_3.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
